{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Demonstrates Creating an Ensemble using Data from Approach 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = pg.connect(database='postgres',\n",
    "                  user='postgres',\n",
    "                  password='w207final',\n",
    "                  host='35.185.225.167')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train/test data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach1TrainingDataQuery = '''  SELECT * FROM  prod.\"features\" f WHERE f.\"Season Type\"='NCAA Tourney' AND f.\"Season\" < 2014 ORDER BY \"Season\", \"DayNum\", \"Team\"  '''\n",
    "df_approach1_training = pd.read_sql_query(approach1TrainingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach1TestingDataQuery = '''  SELECT * FROM  prod.\"features\" f WHERE (f.\"Season Type\"='NCAA Tourney') AND (f.\"Season\">2013 and f.\"Season\"<2018) ORDER BY \"Season\", \"DayNum\", \"Team\"  '''\n",
    "df_approach1_test = pd.read_sql_query(approach1TestingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach2TrainingDataQuery = '''  SELECT * FROM prod.\"features\" f WHERE (f.\"Season Type\"='Regular') OR (f.\"Season\" < 2014) ORDER BY \"Season\", \"DayNum\", \"Team\"  '''\n",
    "df_approach2_training = pd.read_sql_query(approach2TrainingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach2TestingDataQuery = ''' SELECT * FROM prod.\"features\" f WHERE (f.\"Season Type\"='NCAA Tourney') AND (f.\"Season\" > 2013) AND (f.\"Season\" < 2018) order by \"Season\", \"DayNum\", \"Team\" '''\n",
    "df_approach2_test = pd.read_sql_query(approach2TrainingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approach1_training.dropna(how='any', inplace=True, subset=['Outcome', 'AvgRank', 'OpponentAvgRank', 'TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'WinPct', 'OpponentWinPct', 'WinPctDiff', 'AvgPointsFor', 'AvgPointsAgainst', 'AvgNetPointsFor', 'SeedDiff', 'OpponentAvgPointsFor', 'OpponentAvgPointsAgainst', 'OpponentAvgNetPointsFor', 'TourWins', 'OpponentTourWins', 'TourWinsDiff', 'FieldGoalPct_Team', 'TwoPointAttPct_Team', 'ThreePointAttPct_Team', 'FieldGoalAtt_Team', 'TwoPointAtt_Team', 'ThreePointAtt_Team', 'FreeThrowAtt_Team', 'Assists_Team', 'Turnovers_Team', 'Steals_Team', 'Blocks_Team', 'PersonalFouls_Team', 'FieldGoalPct_Opponent', 'TwoPointAttPct_Opponent', 'ThreePointAttPct_Opponent', 'FieldGoalAtt_Opponent', 'TwoPointAtt_Opponent', 'ThreePointAtt_Opponent', 'FreeThrowAtt_Opponent', 'Assists_Opponent', 'Turnovers_Opponent', 'Steals_Opponent', 'Blocks_Opponent', 'PersonalFouls_Opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach1_test.dropna(how='any', inplace=True, subset=['Outcome', 'AvgRank', 'OpponentAvgRank', 'TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'WinPct', 'OpponentWinPct', 'WinPctDiff', 'AvgPointsFor', 'AvgPointsAgainst', 'AvgNetPointsFor', 'SeedDiff', 'OpponentAvgPointsFor', 'OpponentAvgPointsAgainst', 'OpponentAvgNetPointsFor', 'TourWins', 'OpponentTourWins', 'TourWinsDiff', 'FieldGoalPct_Team', 'TwoPointAttPct_Team', 'ThreePointAttPct_Team', 'FieldGoalAtt_Team', 'TwoPointAtt_Team', 'ThreePointAtt_Team', 'FreeThrowAtt_Team', 'Assists_Team', 'Turnovers_Team', 'Steals_Team', 'Blocks_Team', 'PersonalFouls_Team', 'FieldGoalPct_Opponent', 'TwoPointAttPct_Opponent', 'ThreePointAttPct_Opponent', 'FieldGoalAtt_Opponent', 'TwoPointAtt_Opponent', 'ThreePointAtt_Opponent', 'FreeThrowAtt_Opponent', 'Assists_Opponent', 'Turnovers_Opponent', 'Steals_Opponent', 'Blocks_Opponent', 'PersonalFouls_Opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach2_training.dropna(how='any', inplace=True, subset=['Outcome', 'AvgRank', 'OpponentAvgRank', 'TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'WinPct', 'OpponentWinPct', 'WinPctDiff', 'AvgPointsFor', 'AvgPointsAgainst', 'AvgNetPointsFor', 'OpponentAvgPointsFor', 'OpponentAvgPointsAgainst', 'OpponentAvgNetPointsFor', 'TourWins', 'OpponentTourWins', 'TourWinsDiff', 'FieldGoalPct_Team', 'TwoPointAttPct_Team', 'ThreePointAttPct_Team', 'FieldGoalAtt_Team', 'TwoPointAtt_Team', 'ThreePointAtt_Team', 'FreeThrowAtt_Team', 'Assists_Team', 'Turnovers_Team', 'Steals_Team', 'Blocks_Team', 'PersonalFouls_Team', 'FieldGoalPct_Opponent', 'TwoPointAttPct_Opponent', 'ThreePointAttPct_Opponent', 'FieldGoalAtt_Opponent', 'TwoPointAtt_Opponent', 'ThreePointAtt_Opponent', 'FreeThrowAtt_Opponent', 'Assists_Opponent', 'Turnovers_Opponent', 'Steals_Opponent', 'Blocks_Opponent', 'PersonalFouls_Opponent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach2_test.dropna(how='any', inplace=True, subset=['Outcome', 'AvgRank', 'OpponentAvgRank', 'TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'WinPct', 'OpponentWinPct', 'WinPctDiff', 'AvgPointsFor', 'AvgPointsAgainst', 'AvgNetPointsFor', 'OpponentAvgPointsFor', 'OpponentAvgPointsAgainst', 'OpponentAvgNetPointsFor', 'TourWins', 'OpponentTourWins', 'TourWinsDiff', 'FieldGoalPct_Team', 'TwoPointAttPct_Team', 'ThreePointAttPct_Team', 'FieldGoalAtt_Team', 'TwoPointAtt_Team', 'ThreePointAtt_Team', 'FreeThrowAtt_Team', 'Assists_Team', 'Turnovers_Team', 'Steals_Team', 'Blocks_Team', 'PersonalFouls_Team', 'FieldGoalPct_Opponent', 'TwoPointAttPct_Opponent', 'ThreePointAttPct_Opponent', 'FieldGoalAtt_Opponent', 'TwoPointAtt_Opponent', 'ThreePointAtt_Opponent', 'FreeThrowAtt_Opponent', 'Assists_Opponent', 'Turnovers_Opponent', 'Steals_Opponent', 'Blocks_Opponent', 'PersonalFouls_Opponent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target1 = 'Outcome'\n",
    "features1 = ['AvgRank', 'OpponentAvgRank', 'TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'WinPct', 'OpponentWinPct', 'WinPctDiff', 'AvgPointsFor', 'AvgPointsAgainst', 'AvgNetPointsFor', 'SeedDiff', 'OpponentAvgPointsFor', 'OpponentAvgPointsAgainst', 'OpponentAvgNetPointsFor', 'TourWins', 'OpponentTourWins', 'TourWinsDiff', 'FieldGoalPct_Team', 'TwoPointAttPct_Team', 'ThreePointAttPct_Team', 'FieldGoalAtt_Team', 'TwoPointAtt_Team', 'ThreePointAtt_Team', 'FreeThrowAtt_Team', 'Assists_Team', 'Turnovers_Team', 'Steals_Team', 'Blocks_Team', 'PersonalFouls_Team', 'FieldGoalPct_Opponent', 'TwoPointAttPct_Opponent', 'ThreePointAttPct_Opponent', 'FieldGoalAtt_Opponent', 'TwoPointAtt_Opponent', 'ThreePointAtt_Opponent', 'FreeThrowAtt_Opponent', 'Assists_Opponent', 'Turnovers_Opponent', 'Steals_Opponent', 'Blocks_Opponent', 'PersonalFouls_Opponent']\n",
    "\n",
    "target2 = 'Outcome'\n",
    "features2 = ['AvgRank', 'OpponentAvgRank', 'TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'WinPct', 'OpponentWinPct', 'WinPctDiff', 'AvgPointsFor', 'AvgPointsAgainst', 'AvgNetPointsFor', 'OpponentAvgPointsFor', 'OpponentAvgPointsAgainst', 'OpponentAvgNetPointsFor', 'TourWins', 'OpponentTourWins', 'TourWinsDiff', 'FieldGoalPct_Team', 'TwoPointAttPct_Team', 'ThreePointAttPct_Team', 'FieldGoalAtt_Team', 'TwoPointAtt_Team', 'ThreePointAtt_Team', 'FreeThrowAtt_Team', 'Assists_Team', 'Turnovers_Team', 'Steals_Team', 'Blocks_Team', 'PersonalFouls_Team', 'FieldGoalPct_Opponent', 'TwoPointAttPct_Opponent', 'ThreePointAttPct_Opponent', 'FieldGoalAtt_Opponent', 'TwoPointAtt_Opponent', 'ThreePointAtt_Opponent', 'FreeThrowAtt_Opponent', 'Assists_Opponent', 'Turnovers_Opponent', 'Steals_Opponent', 'Blocks_Opponent', 'PersonalFouls_Opponent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = df_approach1_training[features1]\n",
    "y_train1 = df_approach1_training[target1]\n",
    "X_test1 = df_approach1_test[features1]\n",
    "y_test1 = df_approach1_test[target1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2 = df_approach2_training[features2]\n",
    "y_train2 = df_approach2_training[target2]\n",
    "X_test2 = df_approach2_test[features2]\n",
    "y_test2 = df_approach2_test[target2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the same data as X_test1, but has narrower features to support Approach 2 in the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1_2 = df_approach1_test[features2]\n",
    "y_test1_2 = df_approach1_test[target2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1  - (note that this includes 'SeedDiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7048, with best C: 300\n"
     ]
    }
   ],
   "source": [
    "lrc1 = LogisticRegression(penalty='l1')\n",
    "params = {'C': [25,50,75,100,125,150,175,200,225,250,275,300]}\n",
    "gscv1 = GridSearchCV(lrc1, params, scoring='neg_log_loss', refit=True)\n",
    "gscv1.fit(X_train1, y_train1)\n",
    "print('Best neg log-loss: {:.4}, with best C: {}'.format(gscv1.best_score_, gscv1.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73880597014925375"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc1 = LogisticRegression(penalty='l1', C=gscv1.best_params_['C'])\n",
    "lrc1.fit(X_train1, y_train1)\n",
    "lrc1.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74       268\n",
      "          1       0.74      0.74      0.74       268\n",
      "\n",
      "avg / total       0.74      0.74      0.74       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred1 = lrc1.predict(X_test1)\n",
    "y_pred_prob1 = lrc1.predict_proba(X_test1)\n",
    "print(classification_report(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC-AUC score: 0.807\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nROC-AUC score: %.3f\" % roc_auc_score(y_test1, y_pred_prob1[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.530689611158\n",
      "RMSE: 0.179117924015\n"
     ]
    }
   ],
   "source": [
    "# Determine log-loss\n",
    "print 'Log loss: {}'.format(log_loss(y_test1, y_pred_prob1[:,1]))\n",
    "# Determine RMSE\n",
    "print 'RMSE: {}'.format(mean_squared_error(y_test1, y_pred_prob1[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7099, with best C: 75\n"
     ]
    }
   ],
   "source": [
    "lrc2 = LogisticRegression(penalty='l1')\n",
    "params = {'C': [50,75,100,125,150,175,200,225]}\n",
    "gscv2 = GridSearchCV(lrc2, params, scoring='neg_log_loss', refit=True)\n",
    "gscv2.fit(X_train2, y_train2)\n",
    "print('Best neg log-loss: {:.4}, with best C: {}'.format(gscv2.best_score_, gscv2.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102643856920684"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc2 = LogisticRegression(penalty='l1', C=gscv2.best_params_['C'])\n",
    "lrc2.fit(X_train2, y_train2)\n",
    "lrc2.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71     77160\n",
      "          1       0.71      0.71      0.71     77160\n",
      "\n",
      "avg / total       0.71      0.71      0.71    154320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred2 = lrc2.predict(X_test2)\n",
    "y_pred_prob2 = lrc2.predict_proba(X_test2)\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC-AUC score: 0.788\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nROC-AUC score: %.3f\" % roc_auc_score(y_test2, y_pred_prob2[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.551180443636\n",
      "RMSE: 0.18737933068\n"
     ]
    }
   ],
   "source": [
    "# Determine log-loss\n",
    "print 'Log loss: {}'.format(log_loss(y_test2, y_pred_prob2[:,1]))\n",
    "# Determine RMSE\n",
    "print 'RMSE: {}'.format(mean_squared_error(y_test2, y_pred_prob2[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Ensemble of Approach 1 and Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get prediction probabilities from both models\n",
    "probs1 = lrc1.predict_proba(X_test1)\n",
    "probs2 = lrc2.predict_proba(X_test1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mean of the probabilities\n",
    "loss_prob_df = pd.DataFrame(data={'approach1':probs1[:,0], 'approach2':probs2[:,0]})\n",
    "win_prob_df = pd.DataFrame(data={'approach1':probs1[:,1], 'approach2':probs2[:,1]})\n",
    "loss_win_df = pd.DataFrame(data={'loss_prob':loss_prob_df.mean(axis=1), 'win_prob':win_prob_df.mean(axis=1), 'predict':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine loss / win depending on which probability is larger\n",
    "ensemble_predictions = []\n",
    "ensemble_probs = []\n",
    "\n",
    "for index in range(len(win_prob_df)):\n",
    "    if loss_win_df['loss_prob'][index] > loss_win_df['win_prob'][index] :\n",
    "        ensemble_predictions.append(0)\n",
    "        ensemble_probs.append(1-loss_win_df['loss_prob'][index])\n",
    "    else:\n",
    "        ensemble_predictions.append(1)\n",
    "        ensemble_probs.append(loss_win_df['win_prob'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.75      0.75       268\n",
      "          1       0.75      0.75      0.75       268\n",
      "\n",
      "avg / total       0.75      0.75      0.75       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, ensemble_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC-AUC score: 0.816\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nROC-AUC score: %.3f\" % roc_auc_score(y_test1, ensemble_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.524006109785\n",
      "RMSE: 0.175857375446\n"
     ]
    }
   ],
   "source": [
    "# Determine log-loss\n",
    "print 'Log loss: {}'.format(log_loss(y_test1, ensemble_probs))\n",
    "# Determine RMSE\n",
    "print 'RMSE: {}'.format(mean_squared_error(y_test1, ensemble_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
