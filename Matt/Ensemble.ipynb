{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Demonstrates Creating an Ensemble using Data from Approach 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = pg.connect(database='postgres',\n",
    "                  user='postgres',\n",
    "                  password='w207final',\n",
    "                  host='35.185.225.167')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train/test data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach1TrainingDataQuery = '''  SELECT * FROM  prod.\"features\" f WHERE f.\"Season Type\"='NCAA Tourney' AND f.\"Season\" < 2014 ORDER BY \"Season\", \"DayNum\", \"Team\"  '''\n",
    "df_approach1_training = pd.read_sql_query(approach1TrainingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach1TestingDataQuery = '''  SELECT * FROM  prod.\"features\" f WHERE (f.\"Season Type\"='NCAA Tourney') AND (f.\"Season\">2013 and f.\"Season\"<2018) ORDER BY \"Season\", \"DayNum\", \"Team\"  '''\n",
    "df_approach1_test = pd.read_sql_query(approach1TestingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach2TrainingDataQuery = '''  SELECT * FROM prod.\"features\" f WHERE (f.\"Season Type\"='Regular') AND (f.\"Season\" < 2018) ORDER BY \"Season\", \"DayNum\", \"Team\"  '''\n",
    "df_approach2_training = pd.read_sql_query(approach2TrainingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approach2TestingDataQuery = ''' SELECT * FROM prod.\"features\" f WHERE (f.\"Season Type\"='Regular') AND (f.\"Season\" > 2002) order by \"Season\", \"DayNum\", \"Team\" '''\n",
    "df_approach2_test = pd.read_sql_query(approach2TrainingDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach1_training = df_approach1_training.drop( df_approach1_training[\n",
    "                                                                    (np.isnan(df_approach1_training.TwoPointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_training.ThreePointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_training.FreeThrowPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_training.OffensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_training.DefensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_training.TwoPointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_training.ThreePointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_training.FreeThrowPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_training.OffensiveRebounds_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_training.DefensiveRebounds_Opponent))\n",
    "\n",
    "].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach1_test = df_approach1_test.drop( df_approach1_test[\n",
    "                                                                    (np.isnan(df_approach1_test.TwoPointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_test.ThreePointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_test.FreeThrowPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_test.OffensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_test.DefensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach1_test.TwoPointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_test.ThreePointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_test.FreeThrowPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_test.OffensiveRebounds_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach1_test.DefensiveRebounds_Opponent))\n",
    "\n",
    "].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach2_training = df_approach2_training.drop( df_approach2_training[\n",
    "                                                                    (np.isnan(df_approach2_training.TwoPointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_training.ThreePointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_training.FreeThrowPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_training.OffensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_training.DefensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_training.TwoPointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_training.ThreePointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_training.FreeThrowPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_training.OffensiveRebounds_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_training.DefensiveRebounds_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_training.AvgRank)) |\n",
    "                                                                    (np.isnan(df_approach2_training.OpponentAvgRank))\n",
    "].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_approach2_test = df_approach2_test.drop( df_approach2_test[\n",
    "                                                                    (np.isnan(df_approach2_test.TwoPointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_test.ThreePointPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_test.FreeThrowPct_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_test.OffensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_test.DefensiveRebounds_Team)) |\n",
    "                                                                    (np.isnan(df_approach2_test.TwoPointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_test.ThreePointPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_test.FreeThrowPct_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_test.OffensiveRebounds_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_test.DefensiveRebounds_Opponent)) |\n",
    "                                                                    (np.isnan(df_approach2_test.AvgRank)) |\n",
    "                                                                    (np.isnan(df_approach2_test.OpponentAvgRank))\n",
    "].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target1 = 'Outcome'\n",
    "features1 = ['TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'SeedDiff']\n",
    "\n",
    "target2 = 'Outcome'\n",
    "features2 = ['TwoPointPct_Team', 'ThreePointPct_Team', 'FreeThrowPct_Team', 'OffensiveRebounds_Team', 'DefensiveRebounds_Team', 'TwoPointPct_Opponent', 'ThreePointPct_Opponent', 'FreeThrowPct_Opponent', 'OffensiveRebounds_Opponent', 'DefensiveRebounds_Opponent', 'AvgRank', 'OpponentAvgRank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = df_approach1_training[features1]\n",
    "y_train1 = df_approach1_training[target1]\n",
    "X_test1 = df_approach1_test[features1]\n",
    "y_test1 = df_approach1_test[target1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2 = df_approach2_training[features2]\n",
    "y_train2 = df_approach2_training[target2]\n",
    "X_test2 = df_approach2_test[features2]\n",
    "y_test2 = df_approach2_test[target2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the same data as X_test1, but has narrower features to support Approach 2 in the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1_2 = df_approach1_test[features2]\n",
    "y_test1_2 = df_approach1_test[target2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1  - (note that this includes 'SeedDiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best log_loss: 0.716, with best C: 75\n"
     ]
    }
   ],
   "source": [
    "lrc1 = LogisticRegression(penalty='l1')\n",
    "params = {'C': [50,75,100,125,150,175,200,225]}\n",
    "gscv1 = GridSearchCV(lrc1, params, scoring='accuracy', refit=True)\n",
    "gscv1.fit(X_train1, y_train1)\n",
    "print('Best log_loss: {:.4}, with best C: {}'.format(gscv1.best_score_, gscv1.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70522388059701491"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc1 = LogisticRegression(penalty='l1', C=75)\n",
    "lrc1.fit(X_train1, y_train1)\n",
    "lrc1.score(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71       268\n",
      "          1       0.71      0.71      0.71       268\n",
      "\n",
      "avg / total       0.71      0.71      0.71       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred1 = lrc1.predict(X_test1)\n",
    "print(classification_report(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2   - (note that this includes 'AvgRank' and 'OpponentAvgRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best log_loss: 0.7083, with best C: 100\n"
     ]
    }
   ],
   "source": [
    "lrc2 = LogisticRegression(penalty='l1')\n",
    "params = {'C': [50,75,100,125,150,175,200,225]}\n",
    "gscv2 = GridSearchCV(lrc2, params, scoring='accuracy', refit=True)\n",
    "gscv2.fit(X_train2, y_train2)\n",
    "print('Best log_loss: {:.4}, with best C: {}'.format(gscv2.best_score_, gscv2.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70832281941290265"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc2 = LogisticRegression(penalty='l1', C=100)\n",
    "lrc2.fit(X_train2, y_train2)\n",
    "lrc2.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71     71334\n",
      "          1       0.71      0.71      0.71     71334\n",
      "\n",
      "avg / total       0.71      0.71      0.71    142668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred2 = lrc2.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Ensemble of Approach 1 and Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get prediction probabilities from both models\n",
    "probs1 = lrc1.predict_proba(X_test1)\n",
    "probs2 = lrc2.predict_proba(X_test1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mean of the probabilities\n",
    "loss_prob_df = pd.DataFrame(data={'approach1':probs1[:,0], 'approach2':probs2[:,0]})\n",
    "win_prob_df = pd.DataFrame(data={'approach1':probs1[:,1], 'approach2':probs2[:,1]})\n",
    "loss_win_df = pd.DataFrame(data={'loss_prob':loss_prob_df.mean(axis=1), 'win_prob':win_prob_df.mean(axis=1), 'predict':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine loss / win depending on which probability is larger\n",
    "predictions = []\n",
    "\n",
    "for index in range(len(win_prob_df)):\n",
    "    if loss_win_df['loss_prob'][index] > loss_win_df['win_prob'][index] :\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72       268\n",
      "          1       0.72      0.72      0.72       268\n",
      "\n",
      "avg / total       0.72      0.72      0.72       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
